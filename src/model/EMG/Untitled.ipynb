{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f6492c-b1c5-4f16-a069-ab248cc8b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from scipy.signal import spectrogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94001a45-00c5-44f1-b923-f5da35e735cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emg_column(file_path, column=1):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                parts = line.strip().split()\n",
    "                data.append(float(parts[column]))\n",
    "            except:\n",
    "                continue\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e87728-fba5-41e3-a44b-748fed2438a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_emg_signal(signal, label, window_size=1000):\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(0, len(signal) - window_size, window_size):\n",
    "        windows.append(signal[i:i + window_size])\n",
    "        labels.append(label)\n",
    "    return windows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83818c45-1b05-4050-82c7-492ffa4adb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows: 307\n",
      "Shape of each window: (1000,)\n"
     ]
    }
   ],
   "source": [
    "all_windows = []\n",
    "all_labels = []\n",
    "\n",
    "for file, label in [\n",
    "    ('emg_healthy.txt', 0),\n",
    "    ('emg_myopathy.txt', 1),\n",
    "    ('emg_neuropathy.txt', 2)\n",
    "]:\n",
    "    sig = load_emg_column(file)\n",
    "    w, l = window_emg_signal(sig, label)\n",
    "    all_windows.extend(w)\n",
    "    all_labels.extend(l)\n",
    "\n",
    "print(f\"Total windows: {len(all_windows)}\")\n",
    "print(f\"Shape of each window: {all_windows[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d502e43e-5641-452a-800a-d0adc91adbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_emg_as_image(windows, labels, out_dir='emg_images'):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for i, (w, label) in enumerate(zip(windows, labels)):\n",
    "        label_name = {0: \"healthy\", 1: \"myopathy\", 2: \"neuropathy\"}[label]\n",
    "        class_dir = os.path.join(out_dir, label_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Generate spectrogram\n",
    "        f, t, Sxx = spectrogram(w, fs=1000)  # fs can be changed if known\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.pcolormesh(t, f, Sxx, shading='gouraud', cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(class_dir, f\"{label_name}_{i}.png\"), dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7003ba04-ea68-4840-bc0c-6b1b12b66674",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_emg_as_image(all_windows, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1216ab22-1209-4ca3-954a-b4f2297587e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 images belonging to 3 classes.\n",
      "Found 61 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224)\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    'emg_images/',\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    'emg_images/',\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c06903-4282-4f31-9f19-32e8d5e98cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5501 - loss: 2.2412 - val_accuracy: 0.8689 - val_loss: 0.4368\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 949ms/step - accuracy: 0.7844 - loss: 0.4826 - val_accuracy: 0.8689 - val_loss: 0.2196\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8433 - loss: 0.3199 - val_accuracy: 0.9672 - val_loss: 0.1429\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9604 - loss: 0.1582 - val_accuracy: 0.9672 - val_loss: 0.1141\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9663 - loss: 0.1016 - val_accuracy: 0.9508 - val_loss: 0.1468\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9942 - loss: 0.0396 - val_accuracy: 0.9180 - val_loss: 0.2008\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9672 - loss: 0.0993 - val_accuracy: 0.9016 - val_loss: 0.2212\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9118 - loss: 0.2517 - val_accuracy: 0.9344 - val_loss: 0.1525\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8941 - loss: 0.2410 - val_accuracy: 0.8852 - val_loss: 0.2224\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0516 - val_accuracy: 0.9508 - val_loss: 0.1081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22a3aaa55d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(224,224,3)),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e09bafdd-74c2-4478-8b80-24d0d59b1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emg_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6112856-1113-4163-ad19-2c181b1432f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
